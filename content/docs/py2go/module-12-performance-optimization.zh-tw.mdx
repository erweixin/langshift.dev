---
title: "模組 12: 效能優化"
description: "分析和優化 Go 應用程式"
---

## 簡介

Go 是為效能而設計的，但了解如何分析和優化程式碼至關重要。本模組介紹效能分析工具和優化技巧。

## 使用 pprof 進行效能分析

Go 在標準庫中包含了強大的效能分析工具：

<UniversalEditor title="CPU 效能分析">
```python !! py
# Python - cProfile
import cProfile

def my_function():
    # 要分析的程式碼
    pass

cProfile.run('my_function()', 'output.stats')

# 或使用 line_profiler
# @profile
# def my_function():
#     pass
```

```go !! go
// Go - CPU 效能分析
package main

import (
    "os"
    "runtime/pprof"
)

func main() {
    // 開始 CPU 效能分析
    f, _ := os.Create("cpu.prof")
    pprof.StartCPUProfile(f)
    defer pprof.StopCPUProfile()

    // 你的程式碼
    myFunction()
}

// 執行程式後:
// go tool pprof cpu.prof
```
</UniversalEditor>

## 記憶體效能分析

<UniversalEditor title="記憶體效能分析">
```python !! py
# Python - memory_profiler
from memory_profiler import profile

@profile
def my_function():
    data = [x for x in range(1000000)]
    return data

if __name__ == '__main__':
    my_function()
```

```go !! go
// Go - 記憶體效能分析
package main

import (
    "os"
    "runtime/pprof"
)

func main() {
    myFunction()

    // 寫入記憶體效能分析
    f, _ := os.Create("mem.prof")
    pprof.WriteHeapProfile(f)
    f.Close()
}

// 使用以下指令分析:
// go tool pprof mem.prof
```
</UniversalEditor>

## 基準測試和對比

<UniversalEditor title="字串串連基準測試">
```python !! py
# Python - 字串串連
import time

def test_concatenate(n):
    start = time.time()
    result = ""
    for i in range(n):
        result += str(i)
    return time.time() - start

def test_join(n):
    start = time.time()
    parts = [str(i) for i in range(n)]
    result = "".join(parts)
    return time.time() - start

n = 10000
print(f"Concatenate: {test_concatenate(n):.4f}s")
print(f"Join: {test_join(n):.4f}s")

# Concatenate 慢得多！
```

```go !! go
// Go - 字串串連基準測試
package main

import (
    "fmt"
    "strconv"
    "strings"
    "testing"
)

func BenchmarkConcatenate(b *testing.B) {
    for i := 0; i < b.N; i++ {
        result := ""
        for j := 0; j < 100; j++ {
            result += strconv.Itoa(j)
        }
    }
}

func BenchmarkStringsBuilder(b *testing.B) {
    for i := 0; i < b.N; i++ {
        var builder strings.Builder
        for j := 0; j < 100; j++ {
            builder.WriteString(strconv.Itoa(j))
        }
        _ = builder.String()
    }
}

// 執行: go test -bench=.
// BenchmarkConcatenate-8     50000    35000 ns/op
// BenchmarkStringsBuilder-8  500000    3500 ns/op
// Builder 快 10 倍！
```
</UniversalEditor>

## 切片 vs Map 效能

<UniversalEditor title="資料結構效能">
```python !! py
# Python - List vs Dict 查找
import time

def test_list_lookup(n):
    items = list(range(n))
    start = time.time()
    for i in range(n):
        _ = i in items  # O(n) 查找
    return time.time() - start

def test_dict_lookup(n):
    items = {i: i for i in range(n)}
    start = time.time()
    for i in range(n):
        _ = i in items  # O(1) 查找
    return time.time() - start

n = 10000
print(f"List: {test_list_lookup(n):.4f}s")
print(f"Dict: {test_dict_lookup(n):.4f}s")
```

```go !! go
// Go - 切片 vs Map 效能
package main

import "testing"

func BenchmarkSliceLookup(b *testing.B) {
    items := make([]int, 1000)
    for i := range items {
        items[i] = i
    }

    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        for j := 0; j < 1000; j++ {
            _ = contains(items, j)  // O(n)
        }
    }
}

func BenchmarkMapLookup(b *testing.B) {
    items := make(map[int]bool)
    for i := 0; i < 1000; i++ {
        items[i] = true
    }

    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        for j := 0; j < 1000; j++ {
            _ = items[j]  // O(1)
        }
    }
}

func contains(slice []int, item int) bool {
    for _, v := range slice {
        if v == item {
            return true
        }
    }
    return false
}

// Map 在查找方面明顯更快
```
</UniversalEditor>

## Goroutine 池模式

<UniversalEditor title="Goroutine 池">
```python !! py
# Python - ThreadPoolExecutor
from concurrent.futures import ThreadPoolExecutor

def process_task(task_id):
    return task_id * 2

with ThreadPoolExecutor(max_workers=10) as executor:
    results = executor.map(process_task, range(1000))
```

```go !! go
// Go - Worker 池（限制 goroutines）
package main

import (
    "fmt"
    "sync"
    "time"
)

func worker(id int, jobs <-chan int, results chan<- int, wg *sync.WaitGroup) {
    defer wg.Done()
    for job := range jobs {
        // 模擬工作
        time.Sleep(time.Millisecond)
        results <- job * 2
    }
}

func main() {
    jobs := make(chan int, 100)
    results := make(chan int, 100)

    var wg sync.WaitGroup

    // 啟動 10 個 worker（限制 goroutines）
    for w := 1; w <= 10; w++ {
        wg.Add(1)
        go worker(w, jobs, results, &wg)
    }

    // 發送任務
    for j := 0; j < 1000; j++ {
        jobs <- j
    }
    close(jobs)

    // 等待 worker 完成
    go func() {
        wg.Wait()
        close(results)
    }()

    // 收集結果
    for result := range results {
        fmt.Println(result)
    }
}
```
</UniversalEditor>

## 高效的 JSON 處理

<UniversalEditor title="JSON 效能">
```python !! py
# Python - json 模組
import json
import time

data = {"users": [{"id": i, "name": f"User{i}"} for i in range(1000)]}

# 序列化
start = time.time()
json_str = json.dumps(data)
print(f"Serialize: {time.time() - start:.4f}s")

# 反序列化
start = time.time()
parsed = json.loads(json_str)
print(f"Deserialize: {time.time() - start:.4f}s")
```

```go !! go
// Go - 高效的 JSON 串流處理
package main

import (
    "encoding/json"
    "os"
    "testing"
)

type User struct {
    ID   int    `json:"id"`
    Name string `json:"name"`
}

type Data struct {
    Users []User `json:"users"`
}

func BenchmarkJSONMarshal(b *testing.B) {
    users := make([]User, 1000)
    for i := range users {
        users[i] = User{ID: i, Name: fmt.Sprintf("User%d", i)}
    }
    data := Data{Users: users}

    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        json.Marshal(data)
    }
}

func BenchmarkJSONStream(b *testing.B) {
    users := make([]User, 1000)
    for i := range users {
        users[i] = User{ID: i, Name: fmt.Sprintf("User%d", i)}
    }

    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        encoder := json.NewEncoder(os.Stdout)
        encoder.Encode(users)
    }
}

// 串流處理更節省記憶體
```
</UniversalEditor>

## 使用 sync.Map 快取

<UniversalEditor title="並行快取">
```python !! py
# Python - 帶有線程安全的 lru_cache
from functools import lru_cache
import threading

@lru_cache(maxsize=1000)
def expensive_computation(n):
    return n * n

# 或使用自訂快取
cache = {}
lock = threading.Lock()

def get_value(key):
    with lock:
        if key not in cache:
            cache[key] = expensive_computation(key)
        return cache[key]
```

```go !! go
// Go - sync.Map 用於並行存取
package main

import (
    "sync"
    "testing"
)

// 帶互斥鎖的常規 map（大多數情況下更好）
type Cache struct {
    mu   sync.RWMutex
    data map[int]int
}

func NewCache() *Cache {
    return &Cache{
        data: make(map[int]int),
    }
}

func (c *Cache) Get(key int) (int, bool) {
    c.mu.RLock()
    defer c.mu.RUnlock()
    val, ok := c.data[key]
    return val, ok
}

func (c *Cache) Set(key, value int) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.data[key] = value
}

// sync.Map（適合快取類工作負載）
func BenchmarkMapWithMutex(b *testing.B) {
    cache := NewCache()
    cache.Set(1, 100)

    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            cache.Get(1)
        }
    })
}

func BenchmarkSyncMap(b *testing.B) {
    var m sync.Map
    m.Store(1, 100)

    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            m.Load(1)
        }
    })
}
```
</UniversalEditor>

## 避免記憶體分配

<UniversalEditor title="減少分配">
```python !! py
# Python - 重用物件（控制有限）
class Buffer:
    def __init__(self):
        self.data = []

    def process(self, items):
        # 重用列表而不是建立新的
        self.data.clear()
        self.data.extend(items)
        return self.data
```

```go !! go
// Go - 重用緩衝區以減少分配
package main

import "testing"

func AllocateNew() []int {
    // 每次都分配新的
    return make([]int, 1000)
}

var buffer = make([]int, 1000)

func ReuseBuffer() []int {
    // 重用緩衝區（先清零）
    for i := range buffer {
        buffer[i] = 0
    }
    return buffer
}

func BenchmarkAllocate(b *testing.B) {
    for i := 0; i < b.N; i++ {
        _ = AllocateNew()
    }
}

func BenchmarkReuse(b *testing.B) {
    for i := 0; i < b.N; i++ {
        _ = ReuseBuffer()
    }
}

// ReuseBuffer 快得多（無分配）
```
</UniversalEditor>

## 高效的字串操作

<UniversalEditor title="String vs []byte">
```python !! py
# Python - 字串是不可變的
data = "hello world"
# data[0] = 'H'  # TypeError!

# 必須建立新字串
data = "H" + data[1:]

# 對於可變資料，使用 list
chars = list(data)
chars[0] = 'H'
data = ''.join(chars)
```

```go !! go
// Go - 使用 []byte 處理可變資料
package main

import "testing"

func processString(s string) string {
    // 字串是不可變的 - 建立新字串
    return "H" + s[1:]
}

func processBytes(b []byte) []byte {
    // 位元組是可變的 - 原地修改
    if len(b) > 0 {
        b[0] = 'H'
    }
    return b
}

func BenchmarkString(b *testing.B) {
    for i := 0; i < b.N; i++ {
        _ = processString("hello world")
    }
}

func BenchmarkBytes(b *testing.B) {
    for i := 0; i < b.N; i++ {
        data := []byte("hello world")
        _ = processBytes(data)
    }
}

// 位元組版本避免分配
```
</UniversalEditor>

## 效能監控

<UniversalEditor title="執行時指標">
```python !! py
# Python - 使用 psutil 監控
import psutil
import time

def monitor():
    process = psutil.Process()
    print(f"CPU: {process.cpu_percent()}%")
    print(f"Memory: {process.memory_info().rss / 1024 / 1024:.2f} MB")
    print(f"Threads: {process.num_threads()}")
```

```go !! go
// Go - 執行時指標
package main

import (
    "fmt"
    "runtime"
    "time"
)

func main() {
    var m runtime.MemStats

    // 每秒列印統計資訊
    for i := 0; i < 5; i++ {
        runtime.ReadMemStats(&m)

        fmt.Printf("Goroutines: %d\n", runtime.NumGoroutine())
        fmt.Printf("Memory: %.2f MB\n", float64(m.Alloc)/1024/1024)
        fmt.Printf("GC cycles: %d\n", m.NumGC)

        time.Sleep(time.Second)
    }
}
```
</UniversalEditor>

## HTTP 效能技巧

<UniversalEditor title="優化 HTTP 伺服器">
```python !! py
# Python - 效能考慮
from flask import Flask

app = Flask(__name__)

# 使用 JSON 編碼器以提高效能
app.json_encoder = MyCustomEncoder

# 啟用 gzip 壓縮
from flask_compress import Compress
Compress(app)

# 使用連線池
import requests
session = requests.Session()
session.get('http://example.com')
```

```go !! go
// Go - HTTP 效能技巧
package main

import (
    "compress/gzip"
    "net/http"
    "sync"
)

// 連線池
var transport = &http.Transport{
    MaxIdleConns:        100,
    MaxIdleConnsPerHost: 100,
    IdleConnTimeout:     90 * time.Second,
}

var client = &http.Client{
    Transport: transport,
    Timeout:   30 * time.Second,
}

// 回應壓縮
func gzipHandler(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        if acceptsGzip(r) {
            w = gzip.NewWriter(w)
            defer w.(interface{ Flush() }).Flush()
        }
        next.ServeHTTP(w, r)
    })
}

// 重用緩衝區
var bufferPool = sync.Pool{
    New: func() interface{} {
        return make([]byte, 1024)
    },
}

func getBuffer() []byte {
    return bufferPool.Get().([]byte)
}

func putBuffer(b []byte) {
    bufferPool.Put(b)
}
```
</UniversalEditor>

## 總結

在本模組中，你學習了：

1. **CPU 效能分析** 使用 `pprof`
2. **記憶體效能分析** 和堆分析
3. **基準測試** 使用 `testing` 包
4. **字串優化** - 使用 `strings.Builder`
5. **資料結構選擇** - map vs slice
6. **Goroutine 池** - 限制並行
7. **JSON 串流處理** 處理大資料
8. **並行快取** - `sync.Map` vs mutex+map
9. **緩衝區重用** - 減少分配
10. **Byte vs string** - 可變位元組陣列
11. **執行時指標** - 監控效能
12. **HTTP 優化** - 池化、壓縮、重用

## 效能技巧總結

| 領域 | Python | Go 優化 |
|------|--------|---------|
| 字串串連 | 使用 `join()` | 使用 `strings.Builder` |
| 大資料集 | 生成器 | 串流處理、緩衝區 |
| 並行 | `ThreadPoolExecutor` | Worker 池 |
| 快取 | `lru_cache` | `sync.Map` 或 mutex+map |
| 記憶體 | 控制有限 | 緩衝區池、重用 |
| 效能分析 | `cProfile`、`memory_profiler` | 內建 `pprof` |

## 常見效能陷阱

1. **循環中的字串串連** - 使用 `strings.Builder`
2. **過度分配** - 重用緩衝區
3. **無限制的 goroutines** - 使用 worker 池
4. **互斥鎖競爭** - 對讀密集型工作負載使用 RWMutex
5. **select 中阻塞** - 新增 default case 實現非阻塞
6. **大結構體複製** - 使用指標

## 練習

1. 分析 Go 應用程式並找到瓶頸
2. 對不同的字串串連方法進行基準測試
3. 實現 worker 池進行並行處理
4. 優化大檔案的 JSON 處理
5. 比較 sync.Map vs mutex-protected map 的效能

## 下一步

下一模組：**微服務架構** - 使用 Go 建構分散式系統。
